{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de40d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import findspark\n",
    "\n",
    "# Set Java and Spark paths\n",
    "os.environ[\"JAVA_HOME\"] = \"C:\\Program Files\\Java\\jdk-21\"\n",
    "os.environ[\"SPARK_HOME\"] = \"C:\\pyspark\\spark-3.5.0-bin-hadoop3\"\n",
    "\n",
    "# Initialize findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mysql_db_driver_class = \"com.mysql.jdbc.Driver\"\n",
    "# table_name = \"neic_earthquakes\"\n",
    "# host_name = \"localhost\"\n",
    "# port_no = \"3306\"\n",
    "# user_name = \"root\"\n",
    "# password = \"root\"\n",
    "# database_name = \"earthquake_data\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72713bb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Set the path to the MySQL Connector/J JAR file\n",
    "mysql_connector_jar = \"mysql-connector-j-8.0.33.jar\"\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Aidetic\") \\\n",
    "    .config(\"spark.jars\", mysql_connector_jar) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# MySQL connection \n",
    "mysql_url = \"jdbc:mysql://127.0.0.1:3306/earthquake_data\"\n",
    "mysql_properties = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"root\",\n",
    "    \"driver\": \"com.mysql.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "# Read data from MySQL table into PySpark DataFrame\n",
    "initialDF = spark.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", mysql_url) \\\n",
    "    .option(\"dbtable\", \"neic_earthquakes\") \\\n",
    "    .option(\"user\", mysql_properties[\"user\"]) \\\n",
    "    .option(\"password\", mysql_properties[\"password\"]) \\\n",
    "    .option(\"driver\", mysql_properties[\"driver\"]).load()\n",
    "\n",
    "# Show the DataFrame\n",
    "initialDF.show(n=5, truncate=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9aec4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display top 5 records in pandas \n",
    "initialDF.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(initialDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43817d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a72eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = initialDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf1d63",
   "metadata": {},
   "source": [
    "## How does the Day of a Week affect the number of earthquakes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a19b61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1235bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Date\", to_date(\"date\", \"dd/MM/yyyy\"))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b9c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.withColumn('DateOfWeek', dayofweek('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e059fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "\n",
    "# count of week days  \n",
    "result_df = (\n",
    "     df.withColumn('Day', date_format('date', 'E'))\n",
    "    .groupBy('Day')\n",
    "    .count()\n",
    "    .na.drop()\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.toPandas().set_index('Day').plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f81978a",
   "metadata": {},
   "source": [
    "## What is the relation between Day of the month and Number of earthquakes that happened in a year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9089f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract day of month and year from the 'Date' column\n",
    "df = df.withColumn('DayOfMonth', dayofmonth('Date')).withColumn('Year', year('Date'))\n",
    "\n",
    "# Group by year and day of month, then count the number of earthquakes\n",
    "result_df2 = df.groupBy('Year', 'DayOfMonth').count().na.drop().orderBy(\"Year\", \"DayOfMonth\")\n",
    "\n",
    "# Show the result\n",
    "result_df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b30df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "\n",
    "# Calculate correlation between DayOfMonth and count\n",
    "correlation = result_df2.stat.corr('DayOfMonth', 'count')\n",
    "\n",
    "print(f\"Correlation between DayOfMonth and count: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e08306",
   "metadata": {},
   "source": [
    "#### correlation coefficient of -0.01 suggests a very weak negative correlation between the day of the month and the number of earthquakes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8a5903",
   "metadata": {},
   "source": [
    "## What does the average frequency of earthquakes in a month from the year 1965 to 2016  tell us?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc848833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract month and year from the 'Date' column\n",
    "df = df.withColumn('Year', year(\"Date\")).withColumn(\"Month\", month(\"Date\"))\n",
    "\n",
    "# filter Data from year 1965 to 2016\n",
    "filter_df = df.filter((col('Year')>=1965) & (col(\"Year\")<=2016))\n",
    "\n",
    "# frequency of earthquakes by year and month \n",
    "freq_by_month = filter_df.groupBy('Year', 'Month').agg(count('*').alias('Frequency'))\n",
    "\n",
    "# average frequency\n",
    "avg_freq_by_month = (\n",
    "     freq_by_month\n",
    "    .groupBy()\n",
    "    .agg(mean('Frequency').alias('Avg_Frequency')))\n",
    "\n",
    "# Show the result\n",
    "avg_freq_by_month.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc2a96",
   "metadata": {},
   "source": [
    "## What is the relation between Year and Number of earthquakes that happened in that year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564bcb40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Group by year & count the number of earthquakes\n",
    "total_earthquakes = df.groupBy('Year').count().na.drop().orderBy(\"Year\")\n",
    "\n",
    "# Show the result\n",
    "total_earthquakes.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4629101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by year & count the number of earthquakes\n",
    "total_earthquakes = df.groupBy('Year').count().na.drop().orderBy(\"count\", ascending=False).limit(10)\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas DataFrame\n",
    "pandas_df = total_earthquakes.toPandas()\n",
    "\n",
    "# Set the \"Year\" column as the index\n",
    "pandas_df = pandas_df.set_index(\"Year\")\n",
    "\n",
    "# Plot the top 10 years with the highest counts\n",
    "plt.figure(figsize=(12, 15))\n",
    "pandas_df.plot(kind='bar', legend=False)  # Assuming you don't want to show the legend\n",
    "plt.title('Top 10 Years with the Highest Number of Earthquakes')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Earthquakes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e4af3",
   "metadata": {},
   "source": [
    "#### In 2011 higest number of earthquakes happened "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d61b15",
   "metadata": {},
   "source": [
    "## How has the earthquake magnitude on average been varied over the years?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f00b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Group by year and calculate the average magnitude for each year\n",
    "average_magnitude_by_year = df.groupBy('Year').agg(avg('Magnitude').alias('AverageMagnitude'))\n",
    "\n",
    "# Show the result\n",
    "average_magnitude_by_year.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d6f8e3",
   "metadata": {},
   "source": [
    "## How does year impact the standard deviation of the earthquakes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4822d4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the standard deviation of earthquake magnitudes for each year\n",
    "magnitude_std_by_year = df.groupBy('Year').agg(stddev('Magnitude').alias('MagnitudeStdDev')).na.drop()\n",
    "\n",
    "# Show the result\n",
    "magnitude_std_by_year.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42499b9",
   "metadata": {},
   "source": [
    "## Does geographic location have anything to do with earthquakes?\n",
    "\n",
    "Yes, the geographic location is a critical factor in understanding earthquakes. We can plot a world map with the help of geographic location. We can predict in which location the earthquake will happen. I am plotting a simple world map that shows the magnitude of earthquakes as per location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be80098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy(\"Longitude\",\"Latitude\").count().orderBy(\"count\", ascending=False).limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1144ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Magnitude\", df[\"Magnitude\"].cast(\"double\"))\\\n",
    "    .withColumn(\"Longitude\", df[\"Longitude\"].cast(\"double\"))\\\n",
    "    .withColumn(\"Latitude\", df[\"Latitude\"].cast(\"double\"))\n",
    "\n",
    "# Plot the scatter plot\n",
    "df.toPandas().plot(x=\"Longitude\", y=\"Latitude\", kind=\"scatter\", c=\"Magnitude\", colormap=\"YlOrRd\", figsize=(15, 10))\n",
    "plt.title('Earthquake Magnitudes by Location')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce8f2eb",
   "metadata": {},
   "source": [
    "## Where do earthquakes occur very frequently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc390559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, col, desc\n",
    "\n",
    "columns = ['Latitude', 'Longitude', 'Magnitude']\n",
    "\n",
    "# Group by 'Latitude' and 'Longitude', then aggregate sum of 'Magnitude'\n",
    "sorted_earthquake_data = df.select(columns).groupBy('Latitude', 'Longitude')\\\n",
    "                           .agg(count('Magnitude').alias('TotalMagnitude')).na.drop()\\\n",
    "                           .orderBy(col(\"TotalMagnitude\").desc()).limit(1)\n",
    "\n",
    "# Show the sorted DataFrame\n",
    "sorted_earthquake_data.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da6230e",
   "metadata": {},
   "source": [
    "## What is the relation between Magnitude, Magnitude Type , Status and Root Mean Square of the earthquakes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb34171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.select(\"Magnitude\",\"Magnitude_type\",\"Root_Mean_Square\",\"Status\")\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3267bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"Magnitude\", df1[\"Magnitude\"].cast(\"double\"))\n",
    "df1 = df1.withColumn(\"Root_Mean_Square\",df1[\"Root_Mean_Square\"].cast(\"double\"))\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac35257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"Root_Mean_Square\", when(col(\"Root_Mean_Square\")==\"\", np.nan).otherwise(col(\"Root_Mean_Square\")))\n",
    "df1 = df1.withColumn(\"Magnitude\", when(col(\"Magnitude\")==\"\", np.nan).otherwise(col(\"Magnitude\")))\\\n",
    "          .withColumn(\"Magnitude_type\", when(col(\"Magnitude_type\")==\"\", np.nan).otherwise(col(\"Magnitude_type\"))) \\\n",
    "          .withColumn(\"Status\", when(col(\"Status\")==\"\", np.nan).otherwise(col(\"Status\")))\n",
    "df1.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa632d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29288ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = df1.toPandas()\n",
    "\n",
    "# Select numeric columns only\n",
    "numeric_columns = pandas_df.select_dtypes(include='number')\n",
    "\n",
    "# Compute correlation for numeric columns\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035abff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
